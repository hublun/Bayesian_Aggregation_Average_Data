{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hublun/Bayesian_Aggregation_Average_Data/blob/master/NumPyro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the OpenAI Library to Programmatically Access GPT-3.5-turbo!\n",
        "\n",
        "This notebook was authored by [Chris Alexiuk](https://www.linkedin.com/in/csalexiuk/)"
      ],
      "metadata": {
        "id": "kQt-gyAYUbm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwxgaX78E_W0",
        "outputId": "29e8e85b-3f74-484d-f8fa-1da3e191e575"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y4dvNS3FG-u",
        "outputId": "ebeaeede-1029-4ad3-b7df-2539cd5f6b57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 14 18:51:09 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax"
      ],
      "metadata": {
        "id": "R0YddF2vFK71"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jax.devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHBj4Kt4FNjr",
        "outputId": "acf27e9e-f32a-49d2-846f-845660af9eeb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[cuda(id=0)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jax import grad\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def tanh(x):  # Define a function\n",
        "  y = jnp.exp(-2.0 * x)\n",
        "  return (1.0 - y) / (1.0 + y)\n",
        "\n",
        "grad_tanh = grad(tanh)  # Obtain its gradient function\n",
        "print(grad_tanh(1.0))   # Evaluate it at x = 1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfnmtgmYFSoq",
        "outputId": "23bc7da6-6dee-46b7-b890-d7d866fb9233"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4199743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ow840WyUGE3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpyro"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGJ3wbqMFSXC",
        "outputId": "0b327563-ba69-49fc-db62-d85e4b3b34bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpyro\n",
            "  Downloading numpyro-0.13.2-py3-none-any.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.7/312.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax>=0.4.14 in /usr/local/lib/python3.10/dist-packages (from numpyro) (0.4.23)\n",
            "Requirement already satisfied: jaxlib>=0.4.14 in /usr/local/lib/python3.10/dist-packages (from numpyro) (0.4.23+cuda12.cudnn89)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from numpyro) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from numpyro) (1.23.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from numpyro) (4.66.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.14->numpyro) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.14->numpyro) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.14->numpyro) (1.11.4)\n",
            "Installing collected packages: numpyro\n",
            "Successfully installed numpyro-0.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "I4SKfBCSB8ds"
      },
      "outputs": [],
      "source": [
        "import numpyro\n",
        "import numpyro.distributions as dist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numpyro.set_platform('gpu')"
      ],
      "metadata": {
        "id": "5Ql-jUz-nLiB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "J = 8\n",
        "y = np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0])\n",
        "sigma = np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0])"
      ],
      "metadata": {
        "id": "AeIju4Oshk9x"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eight_schools(J, sigma, y=None):\n",
        "    mu = numpyro.sample('mu', dist.Normal(0, 5))\n",
        "    tau = numpyro.sample('tau', dist.HalfCauchy(5))\n",
        "    with numpyro.plate('J', J):\n",
        "      theta = numpyro.sample('theta', dist.Normal(mu, tau))\n",
        "      numpyro.sample('obs', dist.Normal(theta, sigma), obs=y)"
      ],
      "metadata": {
        "id": "8NI4ItZOi2zx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from jax import random\n",
        "from numpyro.infer import MCMC, NUTS"
      ],
      "metadata": {
        "id": "tiqiaqk6iOLo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nuts_kernel = NUTS(eight_schools)\n",
        "mcmc = MCMC(nuts_kernel, num_warmup=500, num_samples=1000)\n",
        "rng_key = random.PRNGKey(0)\n",
        "mcmc.run(rng_key, J, sigma, y=y, extra_fields=('potential_energy',))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DPm0KKwiN7x",
        "outputId": "4c8ec505-0f93-4645-887f-0be9491f2e24"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sample: 100%|██████████| 1500/1500 [00:15<00:00, 96.91it/s, 31 steps of size 1.54e-01. acc. prob=0.84] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcmc.print_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcKAI_dfT0mG",
        "outputId": "43b88418-0470-4ac9-e53b-3f5f52ee1c18"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
            "        mu      5.13      3.30      4.91      0.55     10.78    113.35      1.01\n",
            "       tau      3.88      3.13      2.90      0.61      8.24     74.57      1.00\n",
            "  theta[0]      7.21      5.54      6.68     -2.40     14.98    208.75      1.01\n",
            "  theta[1]      5.62      4.62      5.65     -2.00     12.48    277.16      1.00\n",
            "  theta[2]      4.49      5.61      4.49     -3.65     13.95    216.87      1.00\n",
            "  theta[3]      5.49      4.73      5.39     -2.63     12.32    255.80      1.01\n",
            "  theta[4]      4.22      4.77      4.27     -3.00     11.68    180.66      1.00\n",
            "  theta[5]      5.02      5.01      5.09     -2.34     12.58    229.81      1.00\n",
            "  theta[6]      7.25      4.97      6.96     -0.77     15.21    232.94      1.00\n",
            "  theta[7]      5.71      5.28      5.62     -2.71     12.99    266.35      1.00\n",
            "\n",
            "Number of divergences: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "KNP8-Gk5jcjZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The values above 1 for the split Gelman Rubin diagnostic (r_hat) indicates that the chain has not fully converged. The low value for the effective sample size (n_eff), particularly for tau, and the number of divergent transitions looks problematic.\n",
        "\n",
        "Fortunately, this is a common pathology that can be rectified by using a non-centered paramaterization for tau in our model. This is straightforward to do in NumPyro by using a TransformedDistribution instance together with a reparameterization effect handler. Let us rewrite the same model but instead of sampling theta from a Normal(mu, tau), we will instead sample it from a base Normal(0, 1) distribution that is transformed using an AffineTransform. Note that by doing so, NumPyro runs HMC by generating samples theta_base for the base Normal(0, 1) distribution instead. We see that the resulting chain does not suffer from the same pathology — the Gelman Rubin diagnostic is 1 for all the parameters and the effective sample size looks quite good!"
      ],
      "metadata": {
        "id": "HrPzOqfHUo7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpyro.infer.reparam import TransformReparam, LocScaleReparam\n",
        "\n",
        "# Eight Schools example - Non-centered Reparametrization\n",
        "\n",
        "def eight_schools_noncentered(J, sigma, y=None):\n",
        "\n",
        "    mu = numpyro.sample('mu', dist.Normal(0, 5))\n",
        "    tau = numpyro.sample('tau', dist.HalfCauchy(5))\n",
        "    with numpyro.plate('J', J):\n",
        "        #with numpyro.handlers.reparam(config={'theta': TransformReparam()}):\n",
        "        #  theta = numpyro.sample(\n",
        "        #        'theta',\n",
        "        #        dist.TransformedDistribution(dist.Normal(0., 1.),\n",
        "        #        dist.transforms.AffineTransform(mu, tau)))\n",
        "        with numpyro.handlers.reparam(config={'theta': LocScaleReparam(centered=0)}):\n",
        "          theta = numpyro.sample('theta', dist.Normal(mu, tau))\n",
        "          numpyro.sample('obs', dist.Normal(theta, sigma), obs=y)\n",
        "\n",
        "\n",
        "\n",
        "nuts_kernel = NUTS(eight_schools_noncentered)\n",
        "mcmc = MCMC(nuts_kernel, num_warmup=500, num_samples=1000)\n",
        "rng_key = random.PRNGKey(0)\n",
        "\n",
        "mcmc.run(rng_key, J, sigma, y=y, extra_fields=('potential_energy',))\n",
        "\n",
        "mcmc.print_summary(exclude_deterministic=False)"
      ],
      "metadata": {
        "id": "Ooz5dHAMjb_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8798245-1104-4982-9aff-7f9f358d8d67"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sample: 100%|██████████| 1500/1500 [00:11<00:00, 127.07it/s, 15 steps of size 3.72e-01. acc. prob=0.94]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                         mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
            "                 mu      4.43      3.33      4.52     -1.45      9.13    766.92      1.00\n",
            "                tau      3.65      3.10      2.92      0.00      7.52    563.06      1.00\n",
            "           theta[0]      6.31      5.51      5.86     -2.66     14.55   1009.12      1.00\n",
            "           theta[1]      4.94      4.89      4.84     -2.80     12.35   1031.74      1.01\n",
            "           theta[2]      3.83      5.33      4.05     -5.33     11.57    721.02      1.00\n",
            "           theta[3]      4.91      4.77      4.83     -2.27     12.65   1007.11      1.00\n",
            "           theta[4]      3.68      4.70      3.99     -4.17     11.04    812.73      1.00\n",
            "           theta[5]      4.02      4.76      4.16     -3.64     11.12    845.14      1.00\n",
            "           theta[6]      6.39      4.93      6.00     -1.16     14.38    943.65      1.00\n",
            "           theta[7]      4.45      5.11      4.56     -3.82     11.36    866.83      1.00\n",
            "theta_decentered[0]      0.35      0.96      0.37     -1.24      1.85   1340.15      1.00\n",
            "theta_decentered[1]      0.09      0.97      0.10     -1.38      1.71   1179.32      1.00\n",
            "theta_decentered[2]     -0.15      0.96     -0.17     -1.59      1.54   1372.33      1.00\n",
            "theta_decentered[3]      0.08      0.95      0.07     -1.47      1.59   1339.91      1.00\n",
            "theta_decentered[4]     -0.16      0.95     -0.20     -1.59      1.48   1123.06      1.00\n",
            "theta_decentered[5]     -0.06      0.95     -0.10     -1.62      1.44    907.39      1.00\n",
            "theta_decentered[6]      0.37      0.97      0.40     -1.17      2.03   1066.24      1.00\n",
            "theta_decentered[7]      0.03      0.90      0.02     -1.52      1.43   1078.94      1.00\n",
            "\n",
            "Number of divergences: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let us assume that we have a new school for which we have not observed any test scores, but we would like to generate predictions. NumPyro provides a **Predictive class** for such a purpose. Note that in the* absence of any observed data*, we simply use the population-level parameters to generate predictions. The Predictive utility conditions the unobserved mu and tau sites to values *drawn from the posterior distribution from our last MCMC run*, and runs the model forward to generate predictions."
      ],
      "metadata": {
        "id": "O19A3b1YYBoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpyro.infer import Predictive\n",
        "\n",
        "\n",
        "\n",
        "# New School\n",
        "\n",
        "def new_school():\n",
        "    mu = numpyro.sample('mu', dist.Normal(0, 5))\n",
        "    tau = numpyro.sample('tau', dist.HalfCauchy(5))\n",
        "    return numpyro.sample('obs', dist.Normal(mu, tau))\n",
        "\n",
        "\n",
        "\n",
        "predictive = Predictive(new_school, mcmc.get_samples())\n",
        "\n",
        "samples_predictive = predictive(random.PRNGKey(1))\n",
        "\n",
        "print(np.mean(samples_predictive['obs']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLRBvbBoXj3X",
        "outputId": "2e29b448-b418-4305-ab70-2d020384e7f8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.5687833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PInACkIWUhOd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Our First Prompt\n",
        "\n",
        "You can reference OpenAI's [documentation](https://platform.openai.com/docs/api-reference/authentication?lang=python) if you get stuck!\n",
        "\n",
        "Let's create a `ChatCompletion` model to kick things off!\n",
        "\n",
        "There are three \"roles\" available to use:\n",
        "\n",
        "- `system`\n",
        "- `assistant`\n",
        "- `user`\n",
        "\n",
        "OpenAI provides some context for these roles [here](https://help.openai.com/en/articles/7042661-chatgpt-api-transition-guide)\n",
        "\n",
        "Let's just stick to the `user` role for now and send our first message to the endpoint!\n",
        "\n",
        "If we check the documentation, we'll see that it expects it in a list of prompt objects - so we'll be sure to do that!"
      ],
      "metadata": {
        "id": "T1pOrbwSU5H_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Helper Functions"
      ],
      "metadata": {
        "id": "IB76LJrDVgbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "def get_response(messages: str, model: str = \"gpt-3.5-turbo\") -> str:\n",
        "    return openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "def system_prompt(message: str) -> dict:\n",
        "    return {\"role\": \"system\", \"content\": message}\n",
        "\n",
        "def assistant_prompt(message: str) -> dict:\n",
        "    return {\"role\": \"assistant\", \"content\": message}\n",
        "\n",
        "def user_prompt(message: str) -> dict:\n",
        "    return {\"role\": \"user\", \"content\": message}\n",
        "\n",
        "def pretty_print(message: str) -> str:\n",
        "    display(Markdown(message[\"choices\"][0][\"message\"][\"content\"]))"
      ],
      "metadata": {
        "id": "-vmtUV7WVOLW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}